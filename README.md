# Competitor Monitoring & Contact Scraper

A **Python-based automation pipeline** to monitor competitors using **Google Alerts RSS**, extract relevant news/articles, deduplicate companies, and scrape **official contact information** from competitor websites.

This project is designed for **market intelligence, competitor tracking, and lead research** in domains like **Solar, MNRE, RMS, Remote Monitoring Systems**, etc.

---

## ğŸ”¥ What This Project Does 

1. Reads **Google Alerts RSS feeds** (not email)
2. Unwraps Google redirect URLs to real article links
3. Extracts article content + uses RSS titles as fallback
4. Filters articles using your keywords
5. Deduplicates companies using **domain-based logic**
6. Scrapes competitor **/contact pages** for:

   * Email IDs
   * Phone numbers
   * Address hints
7. Exports clean, structured datasets as CSV

No dashboards. No UI. **Pure data pipeline.**

---

## ğŸ“ Project Folder Structure

```
competitor_monitoring/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ rss_feeds.yaml          # Google Alerts RSS URLs
â”‚   â”œâ”€â”€ keywords.yaml           # Keywords to track
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ news.csv            # Filtered news/articles
â”‚       â”œâ”€â”€ companies.csv       # Deduplicated company list
â”‚       â””â”€â”€ contacts.csv        # Scraped contact details
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Orchestrator (run this)
â”‚   â”œâ”€â”€ fetch_rss.py            # RSS reader
â”‚   â”œâ”€â”€ extract_article.py      # Article text extractor
â”‚   â”œâ”€â”€ url_utils.py            # Google URL un-wrapper
â”‚   â”œâ”€â”€ company_resolver.py     # Domain normalization
â”‚   â”œâ”€â”€ contact_scraper.py      # /contact page scraper
â”‚   â””â”€â”€ exporter.py             # CSV writer
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Requirements

* Python **3.9+** recommended

Install dependencies:

```bash
pip install -r requirements.txt
```

**Required libraries**:

* feedparser
* newspaper3k
* beautifulsoup4
* requests
* pyyaml
* pandas
* tldextract
* phonenumbers
* lxml

---

## ğŸ”§ Configuration

### 1ï¸âƒ£ Google Alerts RSS

Edit:

`config/rss_feeds.yaml`

```yaml
feeds:
  - https://www.google.com/alerts/feeds/XXXXXXXXXXXX
```

> âš ï¸ Alert delivery **must be set to RSS**, not email.

---

### 2ï¸âƒ£ Keywords

Edit:

`config/keywords.yaml`

```yaml
keywords:
  - solar inverter
  - mnre
  - ministry of new and renewable energy
  - rms
  - remote monitoring system
  - datoms
```

Keywords are matched against:

* RSS title
* Extracted article title
* Extracted article body

---

## â–¶ï¸ How to Run

From the project root:

```bash
python src/main.py
```

---

## ğŸ“¤ Output Files

### `news.csv`

Filtered news/articles matching your keywords

| Column           | Description                   |
| ---------------- | ----------------------------- |
| domain           | Source domain                 |
| title            | Article title                 |
| url              | Real article URL              |
| publish_date     | Published date (RSS)          |
| matched_keywords | Keywords that triggered match |

---

### `companies.csv`

Deduplicated company list (domain-based)

| Column     | Description                    |
| ---------- | ------------------------------ |
| domain     | Company domain                 |
| first_seen | First appearance timestamp     |
| last_seen  | Last appearance timestamp      |
| confidence | Data confidence (default: Low) |

---

### `contacts.csv`

Scraped contact details from competitor websites

| Column    | Description              |
| --------- | ------------------------ |
| domain    | Company domain           |
| emails    | Extracted email IDs      |
| phones    | Extracted phone numbers  |
| addresses | Address text (heuristic) |

> âš ï¸ Some sites may return empty fields due to JS rendering or obfuscation.

---

## ğŸ§  Important Design Decisions

* **Domain-based deduplication** â†’ avoids duplicate companies
* **RSS title fallback** â†’ Google Alerts often triggers on title only
* **Google redirect unwrapping** â†’ mandatory for extraction to work
* **Static HTML scraping only** â†’ JS-heavy sites are skipped

This is intentional to keep the system **fast and stable**.

---

## âŒ Known Limitations

* Does NOT handle JS-rendered contact pages (React/Vue)
* Does NOT identify the *actual company mentioned* in articles (publisher â‰  competitor)
* Contact extraction is heuristic, not guaranteed

These are **next-stage upgrades**, not bugs.

---

## ğŸš€ Recommended Next Upgrades

1. Playwright-based contact scraping (JS-safe)
2. Company entity extraction from article text
3. MNRE website crawler (direct, non-RSS)
4. Confidence scoring (High / Medium / Low)
5. Weekly delta exports + dashboard

---

## ğŸ§ª Debugging Tips

If outputs are empty:

1. Open RSS URL in browser â†’ must contain `<entry>` tags
2. Check console logs for `Skipped (no keyword match)`
3. Verify keywords are not overly strict

The pipeline is **input-sensitive by design**.

---

## ğŸ Final Note

This project gives you:

* **Automation**
* **Repeatability**
* **Structured intelligence**

What you do with the data is up to you.

If you donâ€™t act on it, the problem is not the code.
